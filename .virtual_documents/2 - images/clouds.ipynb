from torchvision.datasets import ImageFolder
from torchvision import transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.optim as optim
from torch import tensor


train_transforms = transforms.Compose(
    [
        transforms.ToTensor(),
        transforms.Resize((128, 128)),
    ]
)

dataset_train = ImageFolder(
    "clouds/clouds_train/",
    transform=train_transforms,
)


dataloader_train = DataLoader(
    dataset_train,
    shuffle=True,
    batch_size=1,
)

image, label = next(iter(dataloader_train))
print(image.shape)


image = image.squeeze().permute(1,2,0)
print(image.shape)


plt.imshow(image)
plt.show()


# Data Augmentation

train_transforms = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(45),
    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    transforms.Resize((128, 128)),
])

dataset_train = ImageFolder(
    "clouds/clouds_train",
    transform=train_transforms,
)

dataloader_train = DataLoader(
  dataset_train, shuffle=True, batch_size=1
)

image, label = next(iter(dataloader_train))
print(image.shape)
image = image.squeeze().permute(1,2,0) # Reshape the image tensor from the DataLoader to make it suitable for display
print(image.shape)
plt.imshow(image)
plt.show()


class Net(nn.Module):
    def __init__(self, num_classes):
        # Chama o construtor da classe pai (nn.Module)
        super().__init__()
        # Define a camada de extração de características como uma sequência de operações
        self.feature_extractor = nn.Sequential(
            # Primeira camada convolucional:
                # - Recebe 3 canais de entrada (RGB)
                # - Produz 32 canais de saída (mapas de características)
                # - Usa um kernel de tamanho 3x3 para realizar a convolução
                # - Aplica padding de 1 para manter as dimensões espaciais da saída semelhantes à entrada
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
                # Aplica a função de ativação ELU (Exponential Linear Unit) para introduzir não-linearidade
            nn.ELU(),
                # Aplica uma camada de Max Pooling com um kernel de tamanho 2x2 para reduzir a dimensionalidade espacial
            nn.MaxPool2d(kernel_size=2),
            # Segunda camada convolucional:
                # - Recebe 32 canais de entrada (da camada anterior)
                # - Produz 64 canais de saída
                # - Usa um kernel de tamanho 3x3
                # - Aplica padding de 1
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
                # Aplica a função de ativação ELU novamente
            nn.ELU(),
                # Aplica outra camada de Max Pooling com kernel de tamanho 2x2
            nn.MaxPool2d(kernel_size=2),
                # Achatamento (flatten) da saída das camadas convolucionais em um vetor unidimensional
            nn.Flatten(),
        )
        # Define a camada de classificação como uma camada linear (totalmente conectada)
            # - A entrada tem um tamanho de 64 * 16 * 16 (o número de características após as convoluções e pooling)
            # - A saída tem um tamanho de 'num_classes' (o número de classes que a rede deve prever)
        self.classifier = nn.Linear(64 * 16 * 16, num_classes)

    # Define o método forward, que descreve o fluxo de dados através da rede
    def forward(self, x):
        # Passa a entrada 'x' através da camada de extração de características
        x = self.feature_extractor(x)
        # Passa a saída do extrator de características através da camada de classificação
        x = self.classifier(x)
        # Retorna a saída da camada de classificação (as previsões da rede)
        return x





# Define transforms
train_transforms = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(45),
    transforms.RandomAutocontrast(),
    transforms.ToTensor(),
    transforms.Resize((64, 64)),
])

dataset_train = ImageFolder(
  "clouds/clouds_train",
  transform=train_transforms,
)
dataloader_train = DataLoader(
  dataset_train, shuffle=True, batch_size=16
)


# Rede para 7 categorias
net = Net(num_classes=7)
# Perda para classificação
criterion = nn.CrossEntropyLoss()
# Otimizador para os pesos da rede
optimizer = optim.Adam(net.parameters(), lr=0.001)

# 10 iterações completas no dataset
for epoch in range(10):
    running_loss = 0
    # Para cada grupo de imagens e suas categorias
    for images, labels in dataloader_train:
        # Prepara para calcular novos gradientes
        optimizer.zero_grad()
        # Passa as imagens pela rede
        outputs = net(images)
        # Quão erradas estão as previsões
        loss = criterion(outputs, labels)
        # Calcula a direção para melhorar a rede
        loss.backward()
        # Aplica as melhorias nos pesos
        optimizer.step()
        running_loss += loss.item()
        
    epoch_loss = running_loss / len(dataloader_train)

    print(f"Epoch {epoch+1}, Loss: {epoch_loss:.4f}")


# Define transforms for the test set (no augmentation, just resize and tensor conversion)
test_transforms = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor(),
])

# Cria o dataset e o dataloader para teste
dataset_test = ImageFolder(
    "clouds/clouds_test",  # Certifique-se de que este caminho existe e está estruturado como o de treino
    transform=test_transforms,
)
dataloader_test = DataLoader(
    dataset_test, shuffle=False, batch_size=16
)

import torch
from sklearn.metrics import precision_score, recall_score

# Listas para armazenar as previsões e os rótulos verdadeiros
all_preds = []
all_labels = []

# Coloca a rede em modo de avaliação
net.eval()
# Desativa o cálculo de gradientes (mais rápido e economiza memória)
with torch.no_grad():
    # Para cada lote de imagens e rótulos no conjunto de teste
    for images, labels in dataloader_test:
        # Passa as imagens pela rede para obter as previsões
        outputs = net(images)
        # Obtém a classe prevista para cada imagem
        _, preds = torch.max(outputs, 1)
        # Armazena as previsões e os rótulos verdadeiros
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Calcula precisão e recall (macro para múltiplas classes)
precision = precision_score(all_labels, all_preds, average='macro')
recall = recall_score(all_labels, all_preds, average='macro')

print(f"Precisão: {precision:.4f}")
print(f"Recall: {recall:.4f}")


'''from torchmetrics import Precision, Recall

# Define precision metric for multi-class with 7 classes, averaged using macro
metric_precision = Precision(task="multiclass", num_classes=7, average="macro")
# Define recall metric similarly
metric_recall = Recall(task="multiclass", num_classes=7, average="macro")

# Set the network to evaluation mode (disables dropout, batchnorm behavior)
net.eval()

# Disable gradient calculation during evaluation
with torch.no_grad():
    # Iterate through the test dataloader
    for images, labels in dataloader_test:
        # Get the model's predictions for the input images
        outputs = net(images)
        # Get the predicted class labels (the index of the maximum output probability)
        _, preds = torch.max(outputs, 1)
        # Update the precision metric with the predictions and true labels
        metric_precision(preds, labels)
        # Update the recall metric with the predictions and true labels
        metric_recall(preds, labels)

    # Compute the final precision value over all batches
    precision = metric_precision.compute()
    # Compute the final recall value over all batches
    recall = metric_recall.compute()

    # Print the calculated precision
    print(f"Precision: {precision}")
    # Print the calculated recall
    print(f"Recall: {recall}")'''


from sklearn.metrics import precision_score

# Listas para armazenar as previsões e os rótulos verdadeiros
all_preds = []
all_labels = []

# Coloca a rede em modo de avaliação
net.eval()
with torch.no_grad():
    for images, labels in dataloader_test:
        outputs = net(images)
        _, preds = torch.max(outputs, 1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Calcula precisão por classe (average=None retorna um array com a precisão de cada classe)
precision = precision_score(all_labels, all_preds, average=None)

# Mapeia o nome da classe para o valor de precisão correspondente
precision_per_class = {
    class_name: precision[class_idx].item()
    for class_name, class_idx in dataset_test.class_to_idx.items()
}
print(precision_per_class)


import pandas as pd
import os
import glob
import numpy as np

# Caminho para as imagens de teste organizadas em subpastas por classe
test_root = "clouds/clouds_test"
image_paths = sorted(glob.glob(os.path.join(test_root, "*", "*.jpg")))

# Shuffle para dividir em Public/Private
np.random.seed(42)
shuffled = np.random.permutation(image_paths)
split_idx = len(shuffled) // 2
public_paths = shuffled[:split_idx]
private_paths = shuffled[split_idx:]

data = []

for path in public_paths:
    filename = os.path.basename(path)
    label = os.path.basename(os.path.dirname(path))
    data.append({
        'row_id': filename,   # O nome do arquivo é o ID
        'Usage': 'Public',
        'label': label
    })

for path in private_paths:
    filename = os.path.basename(path)
    label = os.path.basename(os.path.dirname(path))
    data.append({
        'row_id': filename,
        'Usage': 'Private',
        'label': label
    })

solution = pd.DataFrame(data)
solution.to_csv('solution2.csv', index=False)
print("Arquivo solution2.csv gerado com sucesso!")


import pandas as pd

# Supondo que você já tem as listas: filenames, predictions
# filenames: lista dos nomes dos arquivos de teste
# predictions: lista dos rótulos previstos pelo seu modelo

my_submission = pd.DataFrame({
    'row_id': filenames,   # O nome do arquivo é o ID
    'label': predictions
})

my_submission.to_csv('my_submission.csv', index=False)
print("Arquivo my_submission.csv gerado com sucesso!")



